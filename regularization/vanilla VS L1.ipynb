{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c458a6-0a5d-4fa1-8a99-b21f1260e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sgd_vanilla import NeuralNetwork as NN_vanilla\n",
    "from sgd_L1 import NeuralNetwork as NN_L1\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "with open(\"../data/train_data.pkl\", \"rb\") as train_file:\n",
    "    train_data = pickle.load(train_file)\n",
    "\n",
    "with open(\"../data/test_data.pkl\", \"rb\") as test_file:\n",
    "    test_data = pickle.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bd25ee-035b-47e3-98a3-31a527a2f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train stats\n",
      "==> Accuracy: 9.8%, Avg loss: 5.933541\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.764108 [mini-batch 0 / 937]\n",
      "loss: 0.535216 [mini-batch 100 / 937]\n",
      "loss: 0.619163 [mini-batch 200 / 937]\n",
      "loss: 0.831921 [mini-batch 300 / 937]\n",
      "loss: 0.468430 [mini-batch 400 / 937]\n",
      "loss: 0.828165 [mini-batch 500 / 937]\n",
      "loss: 0.439149 [mini-batch 600 / 937]\n",
      "loss: 0.326238 [mini-batch 700 / 937]\n",
      "loss: 0.411431 [mini-batch 800 / 937]\n",
      "loss: 0.591847 [mini-batch 900 / 937]\n",
      "==> Accuracy: 82.2%, Avg loss: 0.501736\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.794793 [mini-batch 0 / 937]\n",
      "loss: 0.391665 [mini-batch 100 / 937]\n",
      "loss: 0.498223 [mini-batch 200 / 937]\n",
      "loss: 0.532885 [mini-batch 300 / 937]\n",
      "loss: 0.587548 [mini-batch 400 / 937]\n",
      "loss: 0.415728 [mini-batch 500 / 937]\n",
      "loss: 0.295454 [mini-batch 600 / 937]\n",
      "loss: 0.312820 [mini-batch 700 / 937]\n",
      "loss: 0.586715 [mini-batch 800 / 937]\n",
      "loss: 0.655655 [mini-batch 900 / 937]\n",
      "==> Accuracy: 81.4%, Avg loss: 0.521637\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.409957 [mini-batch 0 / 937]\n",
      "loss: 0.309107 [mini-batch 100 / 937]\n",
      "loss: 0.426810 [mini-batch 200 / 937]\n",
      "loss: 0.582474 [mini-batch 300 / 937]\n",
      "loss: 0.241379 [mini-batch 400 / 937]\n",
      "loss: 0.332002 [mini-batch 500 / 937]\n",
      "loss: 0.360087 [mini-batch 600 / 937]\n",
      "loss: 0.453309 [mini-batch 700 / 937]\n",
      "loss: 0.338210 [mini-batch 800 / 937]\n",
      "loss: 0.421894 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.441954\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.386117 [mini-batch 0 / 937]\n",
      "loss: 0.537156 [mini-batch 100 / 937]\n",
      "loss: 0.487762 [mini-batch 200 / 937]\n",
      "loss: 0.394211 [mini-batch 300 / 937]\n",
      "loss: 0.350257 [mini-batch 400 / 937]\n",
      "loss: 0.342662 [mini-batch 500 / 937]\n",
      "loss: 0.283269 [mini-batch 600 / 937]\n",
      "loss: 0.388663 [mini-batch 700 / 937]\n",
      "loss: 0.222471 [mini-batch 800 / 937]\n",
      "loss: 0.322946 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.6%, Avg loss: 0.435208\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.413042 [mini-batch 0 / 937]\n",
      "loss: 0.371061 [mini-batch 100 / 937]\n",
      "loss: 0.255480 [mini-batch 200 / 937]\n",
      "loss: 0.296028 [mini-batch 300 / 937]\n",
      "loss: 0.269813 [mini-batch 400 / 937]\n",
      "loss: 0.754935 [mini-batch 500 / 937]\n",
      "loss: 0.527104 [mini-batch 600 / 937]\n",
      "loss: 0.375703 [mini-batch 700 / 937]\n",
      "loss: 0.460324 [mini-batch 800 / 937]\n",
      "loss: 0.417006 [mini-batch 900 / 937]\n",
      "==> Accuracy: 83.5%, Avg loss: 0.461065\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "loss: 0.261633 [mini-batch 0 / 937]\n",
      "loss: 0.402058 [mini-batch 100 / 937]\n",
      "loss: 0.397766 [mini-batch 200 / 937]\n",
      "loss: 0.536790 [mini-batch 300 / 937]\n",
      "loss: 0.372702 [mini-batch 400 / 937]\n",
      "loss: 0.384378 [mini-batch 500 / 937]\n",
      "loss: 0.461396 [mini-batch 600 / 937]\n",
      "loss: 0.522570 [mini-batch 700 / 937]\n",
      "loss: 0.297077 [mini-batch 800 / 937]\n",
      "loss: 0.361216 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.4%, Avg loss: 0.421953\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "loss: 0.451198 [mini-batch 0 / 937]\n",
      "loss: 0.349415 [mini-batch 100 / 937]\n",
      "loss: 0.388295 [mini-batch 200 / 937]\n",
      "loss: 0.317176 [mini-batch 300 / 937]\n",
      "loss: 0.277399 [mini-batch 400 / 937]\n",
      "loss: 0.349927 [mini-batch 500 / 937]\n",
      "loss: 0.452655 [mini-batch 600 / 937]\n",
      "loss: 0.245987 [mini-batch 700 / 937]\n",
      "loss: 0.219941 [mini-batch 800 / 937]\n",
      "loss: 0.369629 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.2%, Avg loss: 0.443097\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "loss: 0.363361 [mini-batch 0 / 937]\n",
      "loss: 0.570689 [mini-batch 100 / 937]\n",
      "loss: 0.362155 [mini-batch 200 / 937]\n",
      "loss: 0.435212 [mini-batch 300 / 937]\n",
      "loss: 0.385477 [mini-batch 400 / 937]\n",
      "loss: 0.576671 [mini-batch 500 / 937]\n",
      "loss: 0.410441 [mini-batch 600 / 937]\n",
      "loss: 0.438804 [mini-batch 700 / 937]\n",
      "loss: 0.573223 [mini-batch 800 / 937]\n",
      "loss: 0.521208 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.3%, Avg loss: 0.440798\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "loss: 0.290613 [mini-batch 0 / 937]\n",
      "loss: 0.485057 [mini-batch 100 / 937]\n",
      "loss: 0.448680 [mini-batch 200 / 937]\n",
      "loss: 0.609505 [mini-batch 300 / 937]\n",
      "loss: 0.416061 [mini-batch 400 / 937]\n",
      "loss: 0.365216 [mini-batch 500 / 937]\n",
      "loss: 0.322025 [mini-batch 600 / 937]\n",
      "loss: 0.368687 [mini-batch 700 / 937]\n",
      "loss: 0.283620 [mini-batch 800 / 937]\n",
      "loss: 0.533935 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.5%, Avg loss: 0.412929\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "loss: 0.398708 [mini-batch 0 / 937]\n",
      "loss: 0.619722 [mini-batch 100 / 937]\n",
      "loss: 0.179319 [mini-batch 200 / 937]\n",
      "loss: 0.353731 [mini-batch 300 / 937]\n",
      "loss: 0.349769 [mini-batch 400 / 937]\n",
      "loss: 0.296605 [mini-batch 500 / 937]\n",
      "loss: 0.470184 [mini-batch 600 / 937]\n",
      "loss: 0.379486 [mini-batch 700 / 937]\n",
      "loss: 0.364144 [mini-batch 800 / 937]\n",
      "loss: 0.395759 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.4%, Avg loss: 0.414663\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "loss: 0.524831 [mini-batch 0 / 937]\n",
      "loss: 0.471449 [mini-batch 100 / 937]\n",
      "loss: 0.359285 [mini-batch 200 / 937]\n",
      "loss: 0.356139 [mini-batch 300 / 937]\n",
      "loss: 0.502537 [mini-batch 400 / 937]\n",
      "loss: 0.446987 [mini-batch 500 / 937]\n",
      "loss: 0.260968 [mini-batch 600 / 937]\n",
      "loss: 0.316806 [mini-batch 700 / 937]\n",
      "loss: 0.307942 [mini-batch 800 / 937]\n",
      "loss: 0.353038 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.0%, Avg loss: 0.425912\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "loss: 0.595762 [mini-batch 0 / 937]\n",
      "loss: 0.244804 [mini-batch 100 / 937]\n",
      "loss: 0.424224 [mini-batch 200 / 937]\n",
      "loss: 0.363449 [mini-batch 300 / 937]\n",
      "loss: 0.314401 [mini-batch 400 / 937]\n",
      "loss: 0.439962 [mini-batch 500 / 937]\n",
      "loss: 0.527721 [mini-batch 600 / 937]\n",
      "loss: 0.375204 [mini-batch 700 / 937]\n",
      "loss: 0.439353 [mini-batch 800 / 937]\n",
      "loss: 0.297813 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.6%, Avg loss: 0.434284\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "loss: 0.362670 [mini-batch 0 / 937]\n",
      "loss: 0.583069 [mini-batch 100 / 937]\n",
      "loss: 0.358117 [mini-batch 200 / 937]\n",
      "loss: 0.378685 [mini-batch 300 / 937]\n",
      "loss: 0.482266 [mini-batch 400 / 937]\n",
      "loss: 0.306751 [mini-batch 500 / 937]\n",
      "loss: 0.561104 [mini-batch 600 / 937]\n",
      "loss: 0.369102 [mini-batch 700 / 937]\n",
      "loss: 0.332118 [mini-batch 800 / 937]\n",
      "loss: 0.364205 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.3%, Avg loss: 0.421733\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "loss: 0.308627 [mini-batch 0 / 937]\n",
      "loss: 0.354167 [mini-batch 100 / 937]\n",
      "loss: 0.222090 [mini-batch 200 / 937]\n",
      "loss: 0.488111 [mini-batch 300 / 937]\n",
      "loss: 0.488801 [mini-batch 400 / 937]\n",
      "loss: 0.293533 [mini-batch 500 / 937]\n",
      "loss: 0.479941 [mini-batch 600 / 937]\n",
      "loss: 0.328471 [mini-batch 700 / 937]\n",
      "loss: 0.464037 [mini-batch 800 / 937]\n",
      "loss: 0.361611 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.1%, Avg loss: 0.422762\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "loss: 0.265468 [mini-batch 0 / 937]\n",
      "loss: 0.457045 [mini-batch 100 / 937]\n",
      "loss: 0.457749 [mini-batch 200 / 937]\n",
      "loss: 0.414260 [mini-batch 300 / 937]\n",
      "loss: 0.274652 [mini-batch 400 / 937]\n",
      "loss: 0.277762 [mini-batch 500 / 937]\n",
      "loss: 0.362487 [mini-batch 600 / 937]\n",
      "loss: 0.389675 [mini-batch 700 / 937]\n",
      "loss: 0.342250 [mini-batch 800 / 937]\n",
      "loss: 0.332563 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.2%, Avg loss: 0.423994\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "loss: 0.618488 [mini-batch 0 / 937]\n",
      "loss: 0.406032 [mini-batch 100 / 937]\n",
      "loss: 0.340981 [mini-batch 200 / 937]\n",
      "loss: 0.378438 [mini-batch 300 / 937]\n",
      "loss: 0.358481 [mini-batch 400 / 937]\n",
      "loss: 0.361535 [mini-batch 500 / 937]\n",
      "loss: 0.215809 [mini-batch 600 / 937]\n",
      "loss: 0.214844 [mini-batch 700 / 937]\n",
      "loss: 0.428524 [mini-batch 800 / 937]\n",
      "loss: 0.282593 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.9%, Avg loss: 0.427921\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "loss: 0.381538 [mini-batch 0 / 937]\n",
      "loss: 0.424502 [mini-batch 100 / 937]\n",
      "loss: 0.299865 [mini-batch 200 / 937]\n",
      "loss: 0.198109 [mini-batch 300 / 937]\n",
      "loss: 0.417458 [mini-batch 400 / 937]\n",
      "loss: 0.356979 [mini-batch 500 / 937]\n",
      "loss: 0.350995 [mini-batch 600 / 937]\n",
      "loss: 0.386475 [mini-batch 700 / 937]\n",
      "loss: 0.633229 [mini-batch 800 / 937]\n",
      "loss: 0.386862 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.434698\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "loss: 0.321774 [mini-batch 0 / 937]\n",
      "loss: 0.335777 [mini-batch 100 / 937]\n",
      "loss: 0.350980 [mini-batch 200 / 937]\n",
      "loss: 0.298357 [mini-batch 300 / 937]\n",
      "loss: 0.271976 [mini-batch 400 / 937]\n",
      "loss: 0.394594 [mini-batch 500 / 937]\n",
      "loss: 0.391016 [mini-batch 600 / 937]\n",
      "loss: 0.347048 [mini-batch 700 / 937]\n",
      "loss: 0.563759 [mini-batch 800 / 937]\n",
      "loss: 0.306099 [mini-batch 900 / 937]\n",
      "==> Accuracy: 83.5%, Avg loss: 0.458108\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "loss: 0.270261 [mini-batch 0 / 937]\n",
      "loss: 0.195900 [mini-batch 100 / 937]\n",
      "loss: 0.587826 [mini-batch 200 / 937]\n",
      "loss: 0.501659 [mini-batch 300 / 937]\n",
      "loss: 0.476512 [mini-batch 400 / 937]\n",
      "loss: 0.391767 [mini-batch 500 / 937]\n",
      "loss: 0.310525 [mini-batch 600 / 937]\n",
      "loss: 0.338092 [mini-batch 700 / 937]\n",
      "loss: 0.259350 [mini-batch 800 / 937]\n",
      "loss: 0.476804 [mini-batch 900 / 937]\n",
      "==> Accuracy: 83.8%, Avg loss: 0.460772\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "loss: 0.586524 [mini-batch 0 / 937]\n",
      "loss: 0.302314 [mini-batch 100 / 937]\n",
      "loss: 0.357086 [mini-batch 200 / 937]\n",
      "loss: 0.327397 [mini-batch 300 / 937]\n",
      "loss: 0.337058 [mini-batch 400 / 937]\n",
      "loss: 0.331931 [mini-batch 500 / 937]\n",
      "loss: 0.272542 [mini-batch 600 / 937]\n",
      "loss: 0.606780 [mini-batch 700 / 937]\n",
      "loss: 0.384575 [mini-batch 800 / 937]\n",
      "loss: 0.453646 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.9%, Avg loss: 0.419148\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "loss: 0.369462 [mini-batch 0 / 937]\n",
      "loss: 0.460829 [mini-batch 100 / 937]\n",
      "loss: 0.635562 [mini-batch 200 / 937]\n",
      "loss: 0.355398 [mini-batch 300 / 937]\n",
      "loss: 0.437246 [mini-batch 400 / 937]\n",
      "loss: 0.360127 [mini-batch 500 / 937]\n",
      "loss: 0.404366 [mini-batch 600 / 937]\n",
      "loss: 0.675895 [mini-batch 700 / 937]\n",
      "loss: 0.418369 [mini-batch 800 / 937]\n",
      "loss: 0.319684 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.5%, Avg loss: 0.437272\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "loss: 0.365866 [mini-batch 0 / 937]\n",
      "loss: 0.581697 [mini-batch 100 / 937]\n",
      "loss: 0.330325 [mini-batch 200 / 937]\n",
      "loss: 0.629443 [mini-batch 300 / 937]\n",
      "loss: 0.481538 [mini-batch 400 / 937]\n",
      "loss: 0.277985 [mini-batch 500 / 937]\n",
      "loss: 0.318290 [mini-batch 600 / 937]\n",
      "loss: 0.536234 [mini-batch 700 / 937]\n",
      "loss: 0.377761 [mini-batch 800 / 937]\n",
      "loss: 0.358628 [mini-batch 900 / 937]\n",
      "==> Accuracy: 81.5%, Avg loss: 0.507041\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "loss: 0.732206 [mini-batch 0 / 937]\n",
      "loss: 0.225610 [mini-batch 100 / 937]\n",
      "loss: 0.507369 [mini-batch 200 / 937]\n",
      "loss: 0.475495 [mini-batch 300 / 937]\n",
      "loss: 0.458525 [mini-batch 400 / 937]\n",
      "loss: 0.236708 [mini-batch 500 / 937]\n",
      "loss: 0.316243 [mini-batch 600 / 937]\n",
      "loss: 0.249647 [mini-batch 700 / 937]\n",
      "loss: 0.325738 [mini-batch 800 / 937]\n",
      "loss: 0.296568 [mini-batch 900 / 937]\n",
      "==> Accuracy: 85.1%, Avg loss: 0.425554\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "loss: 0.248972 [mini-batch 0 / 937]\n",
      "loss: 0.382293 [mini-batch 100 / 937]\n",
      "loss: 0.255893 [mini-batch 200 / 937]\n",
      "loss: 0.502147 [mini-batch 300 / 937]\n",
      "loss: 0.536363 [mini-batch 400 / 937]\n",
      "loss: 0.240549 [mini-batch 500 / 937]\n",
      "loss: 0.519928 [mini-batch 600 / 937]\n",
      "loss: 0.309991 [mini-batch 700 / 937]\n",
      "loss: 0.339126 [mini-batch 800 / 937]\n",
      "loss: 0.610771 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.437768\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "loss: 0.536659 [mini-batch 0 / 937]\n",
      "loss: 0.502627 [mini-batch 100 / 937]\n",
      "loss: 0.553596 [mini-batch 200 / 937]\n",
      "loss: 0.384124 [mini-batch 300 / 937]\n",
      "loss: 0.320236 [mini-batch 400 / 937]\n",
      "loss: 0.324426 [mini-batch 500 / 937]\n",
      "loss: 0.257921 [mini-batch 600 / 937]\n",
      "loss: 0.628651 [mini-batch 700 / 937]\n",
      "loss: 0.385020 [mini-batch 800 / 937]\n",
      "loss: 0.354721 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.3%, Avg loss: 0.440394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train vanilla\n",
    "\n",
    "nn = NN_vanilla(\n",
    "    [28*28, 1024, 512, 128, 10], # layers size\n",
    "    1e-3,                        # learning rate\n",
    "    64,                          # mini batch size\n",
    "    25                           # training epochs\n",
    ")\n",
    "\n",
    "acc_vanilla, loss_vanilla = nn.train(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4386a48-eb43-4990-8461-11e756ce4474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train stats\n",
      "==> Accuracy: 9.4%, Avg loss: 6.897998\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.961504 [mini-batch 0 / 937]\n",
      "loss: 0.812294 [mini-batch 100 / 937]\n",
      "loss: 0.537696 [mini-batch 200 / 937]\n",
      "loss: 0.479131 [mini-batch 300 / 937]\n",
      "loss: 0.445594 [mini-batch 400 / 937]\n",
      "loss: 0.428091 [mini-batch 500 / 937]\n",
      "loss: 0.649495 [mini-batch 600 / 937]\n",
      "loss: 0.485804 [mini-batch 700 / 937]\n",
      "loss: 0.501383 [mini-batch 800 / 937]\n",
      "loss: 0.543127 [mini-batch 900 / 937]\n",
      "==> Accuracy: 80.8%, Avg loss: 0.538538\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.688696 [mini-batch 0 / 937]\n",
      "loss: 0.398265 [mini-batch 100 / 937]\n",
      "loss: 0.610645 [mini-batch 200 / 937]\n",
      "loss: 0.495993 [mini-batch 300 / 937]\n",
      "loss: 0.459594 [mini-batch 400 / 937]\n",
      "loss: 0.418409 [mini-batch 500 / 937]\n",
      "loss: 0.440906 [mini-batch 600 / 937]\n",
      "loss: 0.479756 [mini-batch 700 / 937]\n",
      "loss: 0.280543 [mini-batch 800 / 937]\n",
      "loss: 0.367669 [mini-batch 900 / 937]\n",
      "==> Accuracy: 83.8%, Avg loss: 0.456207\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.401116 [mini-batch 0 / 937]\n",
      "loss: 0.511174 [mini-batch 100 / 937]\n",
      "loss: 0.437712 [mini-batch 200 / 937]\n",
      "loss: 0.428779 [mini-batch 300 / 937]\n",
      "loss: 0.759261 [mini-batch 400 / 937]\n",
      "loss: 0.675364 [mini-batch 500 / 937]\n",
      "loss: 0.286919 [mini-batch 600 / 937]\n",
      "loss: 0.578910 [mini-batch 700 / 937]\n",
      "loss: 0.422991 [mini-batch 800 / 937]\n",
      "loss: 0.466655 [mini-batch 900 / 937]\n",
      "==> Accuracy: 80.4%, Avg loss: 0.514130\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.615058 [mini-batch 0 / 937]\n",
      "loss: 0.360411 [mini-batch 100 / 937]\n",
      "loss: 0.321134 [mini-batch 200 / 937]\n",
      "loss: 0.256133 [mini-batch 300 / 937]\n",
      "loss: 0.321339 [mini-batch 400 / 937]\n",
      "loss: 0.378059 [mini-batch 500 / 937]\n",
      "loss: 0.419211 [mini-batch 600 / 937]\n",
      "loss: 0.338029 [mini-batch 700 / 937]\n",
      "loss: 0.559367 [mini-batch 800 / 937]\n",
      "loss: 0.447951 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.8%, Avg loss: 0.432887\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.317584 [mini-batch 0 / 937]\n",
      "loss: 0.389532 [mini-batch 100 / 937]\n",
      "loss: 0.439361 [mini-batch 200 / 937]\n",
      "loss: 0.371847 [mini-batch 300 / 937]\n",
      "loss: 0.520295 [mini-batch 400 / 937]\n",
      "loss: 0.565480 [mini-batch 500 / 937]\n",
      "loss: 0.257704 [mini-batch 600 / 937]\n",
      "loss: 0.398510 [mini-batch 700 / 937]\n",
      "loss: 0.590592 [mini-batch 800 / 937]\n",
      "loss: 0.305063 [mini-batch 900 / 937]\n",
      "==> Accuracy: 82.9%, Avg loss: 0.462560\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "loss: 0.352582 [mini-batch 0 / 937]\n",
      "loss: 0.370564 [mini-batch 100 / 937]\n",
      "loss: 0.391654 [mini-batch 200 / 937]\n",
      "loss: 0.410237 [mini-batch 300 / 937]\n",
      "loss: 0.473165 [mini-batch 400 / 937]\n",
      "loss: 0.315677 [mini-batch 500 / 937]\n",
      "loss: 0.361789 [mini-batch 600 / 937]\n",
      "loss: 0.476021 [mini-batch 700 / 937]\n",
      "loss: 0.334288 [mini-batch 800 / 937]\n",
      "loss: 0.605511 [mini-batch 900 / 937]\n",
      "==> Accuracy: 83.7%, Avg loss: 0.449694\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "loss: 0.340868 [mini-batch 0 / 937]\n",
      "loss: 0.353184 [mini-batch 100 / 937]\n",
      "loss: 0.328476 [mini-batch 200 / 937]\n",
      "loss: 0.350914 [mini-batch 300 / 937]\n",
      "loss: 0.534392 [mini-batch 400 / 937]\n",
      "loss: 0.409444 [mini-batch 500 / 937]\n",
      "loss: 0.387392 [mini-batch 600 / 937]\n",
      "loss: 0.399756 [mini-batch 700 / 937]\n",
      "loss: 0.301570 [mini-batch 800 / 937]\n",
      "loss: 0.514617 [mini-batch 900 / 937]\n",
      "==> Accuracy: 84.3%, Avg loss: 0.440370\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "loss: 0.394015 [mini-batch 0 / 937]\n",
      "loss: 0.358744 [mini-batch 100 / 937]\n",
      "loss: 0.396006 [mini-batch 200 / 937]\n",
      "loss: 0.537915 [mini-batch 300 / 937]\n",
      "loss: 0.335887 [mini-batch 400 / 937]\n",
      "loss: 0.495349 [mini-batch 500 / 937]\n",
      "loss: 0.432596 [mini-batch 600 / 937]\n",
      "loss: 0.335204 [mini-batch 700 / 937]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train L1 reg\u001b[39;00m\n\u001b[1;32m      3\u001b[0m nn \u001b[38;5;241m=\u001b[39m NN_L1(\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;66;03m# layers size\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m1e-3\u001b[39m,                        \u001b[38;5;66;03m# learning rate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m25\u001b[39m                           \u001b[38;5;66;03m# training epochs\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m acc_L1, loss_L1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fashion_mnist_nn/regularization/sgd_L1.py:128\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, train_data, test_data)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_nabla_z[l] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnabla_z[l]\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_nabla_w[l] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnabla_w[l]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[l] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_nabla_z[l] \u001b[38;5;241m/\u001b[39m n\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train L1 reg\n",
    "\n",
    "nn = NN_L1(\n",
    "    [28*28, 1024, 512, 128, 10], # layers size\n",
    "    1e-3,                        # learning rate\n",
    "    1e-1,                        # L1 lambda\n",
    "    64,                          # mini batch size\n",
    "    25                           # training epochs\n",
    ")\n",
    "\n",
    "acc_L1, loss_L1 = nn.train(train_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
